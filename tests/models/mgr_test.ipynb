{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37453e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the absolute path to the project root\n",
    "notebook_path = Path('/Users/nirmal/Documents/np_research/ManGo_code/ManGo')\n",
    "project_root = str(notebook_path)\n",
    "\n",
    "# Add the project root to Python path if it's not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Now you can import your module\n",
    "from src.models.mg_rig import RobustRegressor\n",
    "\n",
    "# Verify the import worked\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Available at: {RobustRegressor.__module__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dcf712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from src.models.mg_rig import RobustRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate clean data\n",
    "X = np.linspace(0, 2, 10).reshape(-1, 1)\n",
    "y_clean = 10 * X.ravel() + 1  # True linear relationship\n",
    "\n",
    "# Add controlled noise and outliers\n",
    "noise = np.random.normal(0, 2, 10)\n",
    "y_noisy = y_clean + noise\n",
    "# y_noisy[2] += [8.0]  # Add outliers\n",
    "y_noisy[2] = y_noisy[2] + 28.0 \n",
    "\n",
    "# Create test points for smooth curve\n",
    "X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
    "\n",
    "# Fit models\n",
    "degree = 1  # Using degree 1 for linear relationship\n",
    "# Regular polynomial regression\n",
    "poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "poly_reg.fit(X, y_noisy)\n",
    "y_pred_regular = poly_reg.predict(X)\n",
    "y_pred_regular_test = poly_reg.predict(X_test)\n",
    "\n",
    "# Fit robust Machine Gnostics regression\n",
    "mg_model = RobustRegressor(degree=degree, tol=10-8)\n",
    "mg_model.fit(X, y_noisy)\n",
    "y_pred_robust = mg_model.predict(X)\n",
    "y_pred_robust_test = mg_model.predict(X_test)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15))\n",
    "\n",
    "# Plot regression curves\n",
    "ax1.plot(X, y_clean, 'g-', label='True Relationship', linewidth=0.5)\n",
    "ax1.scatter(X, y_noisy, color='gray', label='Noisy Data', zorder=2)\n",
    "ax1.scatter(X[2], y_noisy[2], color='red', s=100, label='Outliers', zorder=3)\n",
    "ax1.plot(X_test, y_pred_regular_test, 'b--', label='Regular Polynomial', zorder=1)\n",
    "ax1.plot(X_test, y_pred_robust_test, 'r-', label='Robust MG', zorder=1)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('Comparison of Regression Methods')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot residuals from true relationship\n",
    "residuals_regular = y_pred_regular - y_clean\n",
    "residuals_robust = y_pred_robust - y_clean\n",
    "ax2.scatter(X, residuals_regular, color='blue', label='Regular Residuals', alpha=0.2)\n",
    "ax2.scatter(X, residuals_robust, color='red', label='Robust Residuals', alpha=0.2)\n",
    "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Residuals from True')\n",
    "ax2.set_title('Residuals from True Relationship')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot sample weights\n",
    "ax3.stem(X.ravel(), mg_model.weights, label='MG Weights')\n",
    "ax3.set_xlabel('X')\n",
    "ax3.set_ylabel('Weight')\n",
    "ax3.set_title('Sample Weights from Robust Regression')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Coefficients:\")\n",
    "print(f\"True:     [1, 2]\")\n",
    "print(f\"Regular:  {poly_reg.named_steps['linearregression'].coef_}\")\n",
    "print(f\"Robust MG: {mg_model.coefficients}\")\n",
    "\n",
    "# Calculate MSE against true relationship\n",
    "mse_regular = np.mean((y_pred_regular[:-2] - y_clean[:-2])**2)\n",
    "mse_robust = np.mean((y_pred_robust[:-2] - y_clean[:-2])**2)\n",
    "print(\"\\nMSE against true relationship (excluding outliers):\")\n",
    "print(f\"Regular Polynomial: {mse_regular:.4f}\")\n",
    "print(f\"Robust MG:         {mse_robust:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ed1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from src.models.mg_rig import RobustRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data\n",
    "X = np.linspace(0, 2, 10).reshape(-1, 1)\n",
    "y = 2.0 * np.exp(1.8 * X.ravel()) + np.random.normal(0, 0.2, 10)\n",
    "# y = 2*X +1\n",
    "y[8:] += [80.0, -8.0]  # Add outliers\n",
    "# Introduce outliers\n",
    "# y[8:] += np.array([8.0, -80.0])  # one high outlier, one low outlier\n",
    "\n",
    "# Create test points for smooth curve\n",
    "X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
    "\n",
    "# Fit regular polynomial regression\n",
    "degree = 2\n",
    "poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "poly_reg.fit(X, y)\n",
    "y_pred_regular = poly_reg.predict(X)  # Predict on training points for residuals\n",
    "y_pred_regular_test = poly_reg.predict(X_test)  # Predict on test points for curve\n",
    "\n",
    "# Fit robust Machine Gnostics regression\n",
    "mg_model = RobustRegressor(degree=degree)\n",
    "mg_model.fit(X, y.flatten())\n",
    "y_pred_robust = mg_model.predict(X)  # Predict on training points for residuals\n",
    "y_pred_robust_test = mg_model.predict(X_test)  # Predict on test points for curve\n",
    "print(f'model coeff: {mg_model.coefficients}')\n",
    "\n",
    "# Calculate residuals\n",
    "residuals_regular = y - y_pred_regular\n",
    "residuals_robust = y - y_pred_robust\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15), height_ratios=[2, 1, 1])\n",
    "\n",
    "# Plot regression curves\n",
    "ax1.scatter(X, y, color='gray', label='Data', zorder=2)\n",
    "ax1.scatter(X[8:], y[8:], color='red', s=100, label='Outliers', zorder=3)\n",
    "ax1.plot(X_test, y_pred_regular_test, 'b--', label='Regular Polynomial', zorder=1)\n",
    "ax1.plot(X_test, y_pred_robust_test, 'r-', label='Robust MG Regression', zorder=1)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('Comparison: Regular vs Robust Machine Gnostics Polynomial Regression')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot residuals\n",
    "ax2.scatter(X, residuals_regular, color='blue', label='Regular Residuals', alpha=0.6)\n",
    "ax2.scatter(X, residuals_robust, color='red', label='Robust Residuals', alpha=0.6)\n",
    "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('Residual Plot')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# plot history of loss\n",
    "ax3.plot(mg_model._history, color='red', label='Loss History - MG Regression')\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Loss')\n",
    "ax3.set_title('Loss History of Robust MG Regression - Average Irrelevance')\n",
    "\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print mean squared error for both methods (excluding outliers)\n",
    "mse_regular = np.mean((y_pred_regular[:-2] - y[:-2])**2)\n",
    "mse_robust = np.mean((y_pred_robust[:-2] - y[:-2])**2)\n",
    "print(f\"MSE (excluding outliers):\")\n",
    "print(f\"Regular Polynomial: {mse_regular:.4f}\")\n",
    "print(f\"Robust MG Regression: {mse_robust:.4f}\")\n",
    "\n",
    "# Print max absolute residuals (excluding outliers)\n",
    "max_resid_regular = np.max(np.abs(residuals_regular[:-2]))\n",
    "max_resid_robust = np.max(np.abs(residuals_robust[:-2]))\n",
    "print(f\"\\nMax Absolute Residuals (excluding outliers):\")\n",
    "print(f\"Regular Polynomial: {max_resid_regular:.4f}\")\n",
    "print(f\"Robust MG Regression: {max_resid_robust:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6edd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ede37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create multiple test functions\n",
    "def generate_data(func_type, X, noise_level=1.8, outlier_positions=[1, 2], outlier_values=[80.0, -15.0]):\n",
    "    if func_type == 'cosine':\n",
    "        y = 15 * np.cos(2 * np.pi * X.ravel()) + 2\n",
    "    elif func_type == 'exponential':\n",
    "        y = 2.0 * np.exp(1.8 * X.ravel())\n",
    "    elif func_type == 'sigmoid':\n",
    "        y = 1.0 * (1 / (1 + np.exp(-5 * (X.ravel() - 1))))\n",
    "    elif func_type == 'polynomial':\n",
    "        y = 0.05 * X.ravel()**3 - 30 * X.ravel()**2 + 1\n",
    "    \n",
    "    y = y + np.random.normal(0, noise_level, len(X))\n",
    "    y[outlier_positions] += outlier_values\n",
    "    return y\n",
    "\n",
    "# Test different functions\n",
    "functions = ['cosine', 'exponential', 'sigmoid', 'polynomial']\n",
    "fig, axes = plt.subplots(len(functions), 2, figsize=(15, 5*len(functions)))\n",
    "\n",
    "# Set regularization parameters\n",
    "alpha_ridge = 1.0\n",
    "alpha_lasso = 0.1\n",
    "\n",
    "for i, func in enumerate(functions):\n",
    "    # Generate data - changed to 5 points\n",
    "    X = np.linspace(0, 2, 6).reshape(-1, 1)  # 5 points total\n",
    "    y = generate_data(func, X)\n",
    "    X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
    "    \n",
    "    # Fit models\n",
    "    degree = 2  # Reduced degree due to fewer points\n",
    "    # Regular polynomial regression\n",
    "    poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_reg.fit(X, y)\n",
    "    y_pred_regular = poly_reg.predict(X)\n",
    "    y_pred_regular_test = poly_reg.predict(X_test)\n",
    "    \n",
    "    # Ridge regression\n",
    "    ridge_reg = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alpha_ridge))\n",
    "    ridge_reg.fit(X, y)\n",
    "    y_pred_ridge = ridge_reg.predict(X)\n",
    "    y_pred_ridge_test = ridge_reg.predict(X_test)\n",
    "    \n",
    "    # Lasso regression\n",
    "    lasso_reg = make_pipeline(PolynomialFeatures(degree), Lasso(alpha=alpha_lasso))\n",
    "    lasso_reg.fit(X, y)\n",
    "    y_pred_lasso = lasso_reg.predict(X)\n",
    "    y_pred_lasso_test = lasso_reg.predict(X_test)\n",
    "    \n",
    "    # Machine Gnostics regression\n",
    "    mg_model = RobustRegressor(degree=degree)\n",
    "    mg_model.fit(X, y)\n",
    "    y_pred_robust = mg_model.predict(X)\n",
    "    y_pred_robust_test = mg_model.predict(X_test)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals_regular = y - y_pred_regular\n",
    "    residuals_ridge = y - y_pred_ridge\n",
    "    residuals_lasso = y - y_pred_lasso\n",
    "    residuals_robust = y - y_pred_robust\n",
    "    \n",
    "    # Plot regression curves\n",
    "    axes[i,0].scatter(X, y, color='gray', label='Data', zorder=2)\n",
    "    # Highlight outliers\n",
    "    axes[i,0].scatter(X[[1, 2]], y[[1, 2]], color='red', s=100, label='Outliers', zorder=3)\n",
    "\n",
    "    axes[i,0].plot(X_test, y_pred_regular_test, 'b--', label='Regular Polynomial', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_ridge_test, 'g-.', label=f'Ridge (α={alpha_ridge})', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_lasso_test, 'm:', label=f'Lasso (α={alpha_lasso})', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_robust_test, 'r-', label='Robust MG', zorder=1)\n",
    "    axes[i,0].set_xlabel('X')\n",
    "    axes[i,0].set_ylabel('y')\n",
    "    axes[i,0].set_title(f'{func.capitalize()} Function')\n",
    "    axes[i,0].legend()\n",
    "    axes[i,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot residuals\n",
    "    axes[i,1].scatter(X, residuals_regular, color='blue', label='Regular', alpha=0.6)\n",
    "    axes[i,1].scatter(X, residuals_ridge, color='green', label='Ridge', alpha=0.6)\n",
    "    axes[i,1].scatter(X, residuals_lasso, color='magenta', label='Lasso', alpha=0.6)\n",
    "    axes[i,1].scatter(X, residuals_robust, color='red', label='MG', alpha=0.6)\n",
    "    axes[i,1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    axes[i,1].set_xlabel('X')\n",
    "    axes[i,1].set_ylabel('Residuals')\n",
    "    axes[i,1].set_title(f'Residuals - {func.capitalize()}')\n",
    "    axes[i,1].legend()\n",
    "    axes[i,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate metrics excluding outliers\n",
    "    good_indices = [0, 2, 4]  # Indices of non-outlier points\n",
    "    mse_regular = np.mean((y_pred_regular[good_indices] - y[good_indices])**2)\n",
    "    mse_ridge = np.mean((y_pred_ridge[good_indices] - y[good_indices])**2)\n",
    "    mse_lasso = np.mean((y_pred_lasso[good_indices] - y[good_indices])**2)\n",
    "    mse_robust = np.mean((y_pred_robust[good_indices] - y[good_indices])**2)\n",
    "    \n",
    "    print(f\"\\n{func.capitalize()} Function:\")\n",
    "    print(f\"MSE (excluding outliers):\")\n",
    "    print(f\"Regular Polynomial: {mse_regular:.4f}\")\n",
    "    print(f\"Ridge Regression:   {mse_ridge:.4f}\")\n",
    "    print(f\"Lasso Regression:   {mse_lasso:.4f}\")\n",
    "    print(f\"Robust MG:          {mse_robust:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "outlier_positions=[2, 7]\n",
    "\n",
    "# Create multiple test functions\n",
    "def generate_data(func_type, X, noise_level=0.9, outlier_positions=outlier_positions, outlier_values=[80.0, -10.0]):\n",
    "    if func_type == 'cosine':\n",
    "        y = 5 * np.cos(2 * np.pi * X.ravel()) + 2\n",
    "    elif func_type == 'exponential':\n",
    "        y = 2.0 * np.exp(1.8 * X.ravel())\n",
    "    elif func_type == 'sigmoid':\n",
    "        y = 10.0 * (1 / (1 + np.exp(-5 * (X.ravel() - 1))))\n",
    "    elif func_type == 'polynomial':\n",
    "        y = 2 * X.ravel()**3 - 3 * X.ravel()**2 + 1\n",
    "    \n",
    "    # Add noise\n",
    "    y = y + np.random.normal(0, noise_level, len(X))\n",
    "    \n",
    "    # Add outliers\n",
    "    y[outlier_positions] += outlier_values\n",
    "    return y\n",
    "\n",
    "# Test different functions\n",
    "functions = ['cosine', 'exponential', 'sigmoid', 'polynomial']\n",
    "fig, axes = plt.subplots(len(functions), 2, figsize=(15, 5*len(functions)))\n",
    "\n",
    "for i, func in enumerate(functions):\n",
    "    # Generate data\n",
    "    X = np.linspace(0, 2, 10).reshape(-1, 1)\n",
    "    y = generate_data(func, X)\n",
    "    X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
    "    \n",
    "    # Fit models\n",
    "    degree = 3  # Increased degree for more complex functions\n",
    "    poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_reg.fit(X, y)\n",
    "    y_pred_regular = poly_reg.predict(X)\n",
    "    y_pred_regular_test = poly_reg.predict(X_test)\n",
    "    \n",
    "    mg_model = RobustRegressor(degree=degree)\n",
    "    mg_model.fit(X, y)\n",
    "    y_pred_robust = mg_model.predict(X)\n",
    "    y_pred_robust_test = mg_model.predict(X_test)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals_regular = y - y_pred_regular\n",
    "    residuals_robust = y - y_pred_robust\n",
    "    \n",
    "    # Plot regression curves\n",
    "    axes[i,0].scatter(X, y, color='gray', label='Data', zorder=2)\n",
    "    # Highlight outliers\n",
    "    axes[i,0].scatter(X[outlier_positions], y[outlier_positions], color='red', s=100, label='Outliers', zorder=3)\n",
    "    # axes[i,0].scatter(X[8:], y[2,8], color='red', s=100, label='Outliers', zorder=3)\n",
    "    axes[i,0].plot(X_test, y_pred_regular_test, 'b--', label='Regular Polynomial', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_robust_test, 'r-', label='Robust MG Regression', zorder=1)\n",
    "    axes[i,0].set_xlabel('X')\n",
    "    axes[i,0].set_ylabel('y')\n",
    "    axes[i,0].set_title(f'{func.capitalize()} Function')\n",
    "    axes[i,0].legend()\n",
    "    axes[i,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot residuals\n",
    "    axes[i,1].scatter(X, residuals_regular, color='blue', label='Regular Residuals', alpha=0.6)\n",
    "    axes[i,1].scatter(X, residuals_robust, color='red', label='Robust Residuals', alpha=0.6)\n",
    "    axes[i,1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    axes[i,1].set_xlabel('X')\n",
    "    axes[i,1].set_ylabel('Residuals')\n",
    "    axes[i,1].set_title(f'Residuals - {func.capitalize()}')\n",
    "    axes[i,1].legend()\n",
    "    axes[i,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Print metrics\n",
    "    mse_regular = np.mean((y_pred_regular[:-2] - y[:-2])**2)\n",
    "    mse_robust = np.mean((y_pred_robust[:-2] - y[:-2])**2)\n",
    "    print(f\"\\n{func.capitalize()} Function:\")\n",
    "    print(f\"MSE (excluding outliers):\")\n",
    "    print(f\"Regular Polynomial: {mse_regular:.4f}\")\n",
    "    print(f\"Robust MG Regression: {mse_robust:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_data(func_type, X, params):\n",
    "    \"\"\"Generate synthetic data with different profiles.\"\"\"\n",
    "    # Base function\n",
    "    if func_type == 'cosine':\n",
    "        y = params['amplitude'] * np.cos(params['frequency'] * X.ravel()) + params['offset']\n",
    "    elif func_type == 'exponential':\n",
    "        y = params['amplitude'] * np.exp(params['rate'] * X.ravel())\n",
    "    elif func_type == 'sigmoid':\n",
    "        y = params['amplitude'] / (1 + np.exp(-params['rate'] * (X.ravel() - params['midpoint'])))\n",
    "    elif func_type == 'polynomial':\n",
    "        y = (params['a'] * X.ravel()**3 + \n",
    "             params['b'] * X.ravel()**2 + \n",
    "             params['c'] * X.ravel() + \n",
    "             params['d'])\n",
    "    \n",
    "    # Add base noise\n",
    "    y_ = y + np.random.normal(0, params['noise_level'], len(X))\n",
    "    \n",
    "    # Add trend if specified\n",
    "    if params['trend'] != 0:\n",
    "        y_ += params['trend'] * X.ravel()\n",
    "    \n",
    "    # Add outliers\n",
    "    if params['outlier_mode'] == 'random':\n",
    "        # Random outliers\n",
    "        n_outliers = int(len(X) * params['outlier_fraction'])\n",
    "        outlier_idx = np.random.choice(len(X), n_outliers, replace=False)\n",
    "        outlier_values = np.random.normal(params['outlier_mean'], \n",
    "                                        params['outlier_std'], \n",
    "                                        n_outliers)\n",
    "        y_[outlier_idx] += outlier_values\n",
    "    elif params['outlier_mode'] == 'systematic':\n",
    "        # Systematic outliers at specific positions\n",
    "        y_[params['outlier_positions']] += params['outlier_values']\n",
    "    \n",
    "    return y, y_\n",
    "\n",
    "# Define test profiles with different characteristics\n",
    "test_profiles = {\n",
    "    'cosine': {\n",
    "        'amplitude': 15,\n",
    "        'frequency': 2 * np.pi,\n",
    "        'offset': 2,\n",
    "        'noise_level': 5,\n",
    "        'trend': 2,  # Linear trend\n",
    "        'outlier_mode': 'random',\n",
    "        'outlier_fraction': 0.1,\n",
    "        'outlier_mean': 0,\n",
    "        'outlier_std': 50\n",
    "    },\n",
    "    'exponential': {\n",
    "        'amplitude': 2,\n",
    "        'rate': 1.8,\n",
    "        'noise_level': 8,\n",
    "        'trend': -1,  # Negative trend\n",
    "        'outlier_mode': 'systematic',\n",
    "        'outlier_positions': [20, 40, 60, 80],\n",
    "        'outlier_values': [80, -60, 100, -80]\n",
    "    },\n",
    "    'sigmoid': {\n",
    "        'amplitude': 100,\n",
    "        'rate': 5,\n",
    "        'midpoint': 1,\n",
    "        'noise_level': 10,\n",
    "        'trend': 0,\n",
    "        'outlier_mode': 'random',\n",
    "        'outlier_fraction': 0.15,\n",
    "        'outlier_mean': 50,\n",
    "        'outlier_std': 30\n",
    "    },\n",
    "    'polynomial': {\n",
    "        'a': 0.005,\n",
    "        'b': -0.3,\n",
    "        'c': 5,\n",
    "        'd': 70,\n",
    "        'noise_level': 15,\n",
    "        'trend': 1.5,\n",
    "        'outlier_mode': 'systematic',\n",
    "        'outlier_positions': [10, 30, 50, 70, 90],\n",
    "        'outlier_values': [-60, 80, -70, 90, -50]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test different functions\n",
    "functions = ['cosine', 'exponential', 'sigmoid', 'polynomial']\n",
    "fig, axes = plt.subplots(len(functions), 2, figsize=(15, 5*len(functions)))\n",
    "\n",
    "# Set regularization parameters\n",
    "alpha_ridge = 1.0\n",
    "alpha_lasso = 0.1\n",
    "\n",
    "for i, func in enumerate(functions):\n",
    "    # Generate data\n",
    "    X = np.linspace(0, 2, 100).reshape(-1, 1)\n",
    "    y, y_ = generate_data(func, X, test_profiles[func])\n",
    "    X_test = np.linspace(0, 2, 200).reshape(-1, 1)\n",
    "    \n",
    "    # ... rest of the code remains the same ...\n",
    "    \n",
    "    # Fit models\n",
    "    degree = 5  # Reduced degree due to fewer points\n",
    "    # Regular polynomial regression\n",
    "    poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_reg.fit(X, y)\n",
    "    y_pred_regular = poly_reg.predict(X)\n",
    "    y_pred_regular_test = poly_reg.predict(X_test)\n",
    "    \n",
    "    # Ridge regression\n",
    "    ridge_reg = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alpha_ridge))\n",
    "    ridge_reg.fit(X, y)\n",
    "    y_pred_ridge = ridge_reg.predict(X)\n",
    "    y_pred_ridge_test = ridge_reg.predict(X_test)\n",
    "    \n",
    "    # Lasso regression\n",
    "    lasso_reg = make_pipeline(PolynomialFeatures(degree), Lasso(alpha=alpha_lasso))\n",
    "    lasso_reg.fit(X, y)\n",
    "    y_pred_lasso = lasso_reg.predict(X)\n",
    "    y_pred_lasso_test = lasso_reg.predict(X_test)\n",
    "    \n",
    "    # Machine Gnostics regression\n",
    "    mg_model = RobustRegressor(degree=degree)\n",
    "    mg_model.fit(X, y)\n",
    "    y_pred_robust = mg_model.predict(X)\n",
    "    y_pred_robust_test = mg_model.predict(X_test)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals_regular = y - y_pred_regular\n",
    "    residuals_ridge = y - y_pred_ridge\n",
    "    residuals_lasso = y - y_pred_lasso\n",
    "    residuals_robust = y - y_pred_robust\n",
    "    \n",
    "    # Plot regression curves\n",
    "    axes[i,0].scatter(X, y_, color='gray', label='Data', zorder=2, alpha=0.3)\n",
    "    # true data\n",
    "    axes[i,0].plot(X, y, color='g', label='Data', zorder=2, alpha=0.3)\n",
    "    # true data)\n",
    "\n",
    "    axes[i,0].plot(X_test, y_pred_regular_test, 'b--', label='Regular Polynomial', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_ridge_test, 'g-.', label=f'Ridge (α={alpha_ridge})', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_lasso_test, 'm:', label=f'Lasso (α={alpha_lasso})', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_robust_test, 'r-', label='Robust MG', zorder=1)\n",
    "    axes[i,0].set_xlabel('X')\n",
    "    axes[i,0].set_ylabel('y')\n",
    "    axes[i,0].set_title(f'{func.capitalize()} Function')\n",
    "    axes[i,0].legend()\n",
    "    axes[i,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot residuals\n",
    "    axes[i,1].scatter(X, residuals_regular, color='blue', label='Regular', alpha=0.3)\n",
    "    axes[i,1].scatter(X, residuals_ridge, color='green', label='Ridge', alpha=0.63)\n",
    "    axes[i,1].scatter(X, residuals_lasso, color='magenta', label='Lasso', alpha=0.3)\n",
    "    axes[i,1].scatter(X, residuals_robust, color='red', label='MG', alpha=0.3)\n",
    "    axes[i,1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    axes[i,1].set_xlabel('X')\n",
    "    axes[i,1].set_ylabel('Residuals')\n",
    "    axes[i,1].set_title(f'Residuals - {func.capitalize()}')\n",
    "    axes[i,1].legend()\n",
    "    axes[i,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate metrics excluding outliers\n",
    "    good_indices = [0, 2, 4]  # Indices of non-outlier points\n",
    "    mse_regular = np.mean((y_pred_regular[good_indices] - y[good_indices])**2)\n",
    "    mse_ridge = np.mean((y_pred_ridge[good_indices] - y[good_indices])**2)\n",
    "    mse_lasso = np.mean((y_pred_lasso[good_indices] - y[good_indices])**2)\n",
    "    mse_robust = np.mean((y_pred_robust[good_indices] - y[good_indices])**2)\n",
    "    \n",
    "    print(f\"\\n{func.capitalize()} Function:\")\n",
    "    print(f\"MSE (excluding outliers):\")\n",
    "    print(f\"Regular Polynomial: {mse_regular:.4f}\")\n",
    "    print(f\"Ridge Regression:   {mse_ridge:.4f}\")\n",
    "    print(f\"Lasso Regression:   {mse_lasso:.4f}\")\n",
    "    print(f\"Robust MG:          {mse_robust:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccdbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(func_type, X, params):\n",
    "    \"\"\"Generate synthetic data with different profiles and outlier clusters.\"\"\"\n",
    "    # Base function\n",
    "    if func_type == 'cosine':\n",
    "        y = params['amplitude'] * np.cos(params['frequency'] * X.ravel()) + params['offset']\n",
    "    elif func_type == 'exponential':\n",
    "        y = params['amplitude'] * np.exp(params['rate'] * X.ravel())\n",
    "    elif func_type == 'sigmoid':\n",
    "        y = params['amplitude'] / (1 + np.exp(-params['rate'] * (X.ravel() - params['midpoint'])))\n",
    "    elif func_type == 'polynomial':\n",
    "        y = (params['a'] * X.ravel()**3 + \n",
    "             params['b'] * X.ravel()**2 + \n",
    "             params['c'] * X.ravel() + \n",
    "             params['d'])\n",
    "    \n",
    "    # Add base noise\n",
    "    y_ = y + np.random.normal(0, params['noise_level'], len(X))\n",
    "    \n",
    "    # Add trend if specified\n",
    "    if params['trend'] != 0:\n",
    "        y_ += params['trend'] * X.ravel()\n",
    "    \n",
    "    # Add outlier clusters\n",
    "    for cluster in params['outlier_clusters']:\n",
    "        center = cluster['center']\n",
    "        width = cluster['width']\n",
    "        strength = cluster['strength']\n",
    "        \n",
    "        # Create cluster of outliers\n",
    "        cluster_mask = np.abs(X.ravel() - center) < width/2\n",
    "        n_points = np.sum(cluster_mask)\n",
    "        \n",
    "        if n_points > 0:\n",
    "            # Generate cluster noise\n",
    "            cluster_noise = np.random.normal(\n",
    "                strength['mean'], \n",
    "                strength['std'], \n",
    "                n_points\n",
    "            )\n",
    "            y[cluster_mask] += cluster_noise\n",
    "    \n",
    "    return y, y_\n",
    "\n",
    "# Define test profiles with outlier clusters\n",
    "test_profiles = {\n",
    "    'cosine': {\n",
    "        'amplitude': 15,\n",
    "        'frequency': 2 * np.pi,\n",
    "        'offset': 2,\n",
    "        'noise_level': 5,\n",
    "        'trend': 2,\n",
    "        'outlier_clusters': [\n",
    "            {'center': 0.5, 'width': 0.2, 'strength': {'mean': 30, 'std': 10}},\n",
    "            # {'center': 1.2, 'width': 0.3, 'strength': {'mean': -40, 'std': 15}},\n",
    "            # {'center': 1.8, 'width': 0.2, 'strength': {'mean': 60, 'std': 12}}\n",
    "        ]\n",
    "    },\n",
    "    'exponential': {\n",
    "        'amplitude': 2,\n",
    "        'rate': 1.8,\n",
    "        'noise_level': 8,\n",
    "        'trend': -1,\n",
    "        'outlier_clusters': [\n",
    "            # {'center': 0.3, 'width': 0.25, 'strength': {'mean': -60, 'std': 15}},\n",
    "            {'center': 1.0, 'width': 0.2, 'strength': {'mean': 80, 'std': 20}},\n",
    "            # {'center': 1.7, 'width': 0.3, 'strength': {'mean': -70, 'std': 18}}\n",
    "        ]\n",
    "    },\n",
    "    'sigmoid': {\n",
    "        'amplitude': 100,\n",
    "        'rate': 5,\n",
    "        'midpoint': 1,\n",
    "        'noise_level': 10,\n",
    "        'trend': 0,\n",
    "        'outlier_clusters': [\n",
    "            {'center': 0.4, 'width': 0.2, 'strength': {'mean': 90, 'std': 15}},\n",
    "            # {'center': 1.1, 'width': 0.25, 'strength': {'mean': -50, 'std': 12}},\n",
    "            # {'center': 1.6, 'width': 0.3, 'strength': {'mean': 40, 'std': 10}}\n",
    "        ]\n",
    "    },\n",
    "    'polynomial': {\n",
    "        'a': 0.005,\n",
    "        'b': -0.3,\n",
    "        'c': 5,\n",
    "        'd': 70,\n",
    "        'noise_level': 15,\n",
    "        'trend': 1.5,\n",
    "        'outlier_clusters': [\n",
    "            # {'center': 0.6, 'width': 0.3, 'strength': {'mean': -80, 'std': 20}},\n",
    "            {'center': 1.3, 'width': 0.2, 'strength': {'mean': 90, 'std': 15}},\n",
    "            # {'center': 1.9, 'width': 0.25, 'strength': {'mean': -60, 'std': 18}}\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c34b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different functions\n",
    "functions = ['cosine', 'exponential', 'sigmoid', 'polynomial']\n",
    "fig, axes = plt.subplots(len(functions), 2, figsize=(15, 5*len(functions)))\n",
    "\n",
    "# Set regularization parameters\n",
    "alpha_ridge = 1.0\n",
    "alpha_lasso = 0.1\n",
    "\n",
    "for i, func in enumerate(functions):\n",
    "    # Generate data\n",
    "    X = np.linspace(0, 2, 100).reshape(-1, 1)\n",
    "    y, y_clean = generate_data(func, X, test_profiles[func])\n",
    "    X_test = np.linspace(0, 2, 200).reshape(-1, 1)\n",
    "    \n",
    "    # ... rest of the code remains the same ...\n",
    "    \n",
    "    # Fit models\n",
    "    degree = 3  # Reduced degree due to fewer points\n",
    "    # Regular polynomial regression\n",
    "    poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_reg.fit(X, y)\n",
    "    y_pred_regular = poly_reg.predict(X)\n",
    "    y_pred_regular_test = poly_reg.predict(X_test)\n",
    "    \n",
    "    # Ridge regression\n",
    "    ridge_reg = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alpha_ridge))\n",
    "    ridge_reg.fit(X, y)\n",
    "    y_pred_ridge = ridge_reg.predict(X)\n",
    "    y_pred_ridge_test = ridge_reg.predict(X_test)\n",
    "    \n",
    "    # Lasso regression\n",
    "    lasso_reg = make_pipeline(PolynomialFeatures(degree), Lasso(alpha=alpha_lasso))\n",
    "    lasso_reg.fit(X, y)\n",
    "    y_pred_lasso = lasso_reg.predict(X)\n",
    "    y_pred_lasso_test = lasso_reg.predict(X_test)\n",
    "    \n",
    "    # Machine Gnostics regression\n",
    "    mg_model = RobustRegressor(degree=degree)\n",
    "    mg_model.fit(X, y)\n",
    "    y_pred_robust = mg_model.predict(X)\n",
    "    y_pred_robust_test = mg_model.predict(X_test)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals_regular = y - y_pred_regular\n",
    "    residuals_ridge = y - y_pred_ridge\n",
    "    residuals_lasso = y - y_pred_lasso\n",
    "    residuals_robust = y - y_pred_robust\n",
    "    \n",
    "    # Plot regression curves\n",
    "    axes[i,0].scatter(X, y, color='gray', label='Data', zorder=2, alpha=0.3)\n",
    "    # line plot -true data\n",
    "    axes[i,0].plot(X, y_clean, color='g', alpha=0.1, label='True Data', zorder=2)\n",
    "    # Highlight outliers\n",
    "    # axes[i,0].scatter(X[[1, 2]], y[[1, 2]], color='red', s=100, label='Outliers', zorder=3)\n",
    "\n",
    "    axes[i,0].plot(X_test, y_pred_regular_test, 'b--', label='Regular Polynomial', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_ridge_test, 'g-.', label=f'Ridge (α={alpha_ridge})', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_lasso_test, 'm:', label=f'Lasso (α={alpha_lasso})', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_robust_test, 'r-', label='Robust MG', zorder=1)\n",
    "    axes[i,0].set_xlabel('X')\n",
    "    axes[i,0].set_ylabel('y')\n",
    "    axes[i,0].set_title(f'{func.capitalize()} Function')\n",
    "    axes[i,0].legend()\n",
    "    axes[i,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot residuals\n",
    "    axes[i,1].scatter(X, residuals_regular, color='blue', label='Regular', alpha=0.3)\n",
    "    axes[i,1].scatter(X, residuals_ridge, color='green', label='Ridge', alpha=0.63)\n",
    "    axes[i,1].scatter(X, residuals_lasso, color='magenta', label='Lasso', alpha=0.3)\n",
    "    axes[i,1].scatter(X, residuals_robust, color='red', label='MG', alpha=0.3)\n",
    "    axes[i,1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    axes[i,1].set_xlabel('X')\n",
    "    axes[i,1].set_ylabel('Residuals')\n",
    "    axes[i,1].set_title(f'Residuals - {func.capitalize()}')\n",
    "    axes[i,1].legend()\n",
    "    axes[i,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate metrics excluding outliers\n",
    "    good_indices = [0, 2, 4]  # Indices of non-outlier points\n",
    "    mse_regular = np.mean((y_pred_regular[good_indices] - y[good_indices])**2)\n",
    "    mse_ridge = np.mean((y_pred_ridge[good_indices] - y[good_indices])**2)\n",
    "    mse_lasso = np.mean((y_pred_lasso[good_indices] - y[good_indices])**2)\n",
    "    mse_robust = np.mean((y_pred_robust[good_indices] - y[good_indices])**2)\n",
    "    \n",
    "    print(f\"\\n{func.capitalize()} Function:\")\n",
    "    print(f\"MSE (excluding outliers):\")\n",
    "    print(f\"Regular Polynomial: {mse_regular:.4f}\")\n",
    "    print(f\"Ridge Regression:   {mse_ridge:.4f}\")\n",
    "    print(f\"Lasso Regression:   {mse_lasso:.4f}\")\n",
    "    print(f\"Robust MG:          {mse_robust:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different functions\n",
    "functions = ['cosine', 'exponential', 'sigmoid', 'polynomial']\n",
    "fig, axes = plt.subplots(len(functions), 4, figsize=(25, 5*len(functions)))\n",
    "\n",
    "# Set regularization parameters\n",
    "alpha_ridge = 1.0\n",
    "alpha_lasso = 0.1\n",
    "\n",
    "for i, func in enumerate(functions):\n",
    "    # Generate data\n",
    "    X = np.linspace(0, 2, 100).reshape(-1, 1)\n",
    "    y, y_clean = generate_data(func, X, test_profiles[func])\n",
    "    X_test = np.linspace(0, 2, 200).reshape(-1, 1)\n",
    "    \n",
    "    # Fit models\n",
    "    degree = 3  # Reduced degree due to fewer points\n",
    "    \n",
    "    # Regular polynomial regression\n",
    "    poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_reg.fit(X, y)\n",
    "    y_pred_regular = poly_reg.predict(X)\n",
    "    y_pred_regular_test = poly_reg.predict(X_test)\n",
    "    \n",
    "    # Ridge regression\n",
    "    ridge_reg = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alpha_ridge))\n",
    "    ridge_reg.fit(X, y)\n",
    "    y_pred_ridge = ridge_reg.predict(X)\n",
    "    y_pred_ridge_test = ridge_reg.predict(X_test)\n",
    "    \n",
    "    # Lasso regression\n",
    "    lasso_reg = make_pipeline(PolynomialFeatures(degree), Lasso(alpha=alpha_lasso))\n",
    "    lasso_reg.fit(X, y)\n",
    "    y_pred_lasso = lasso_reg.predict(X)\n",
    "    y_pred_lasso_test = lasso_reg.predict(X_test)\n",
    "    \n",
    "    # Machine Gnostics regression\n",
    "    mg_model = RobustRegressor(degree=degree)\n",
    "    mg_model.fit(X, y)\n",
    "    y_pred_robust = mg_model.predict(X)\n",
    "    y_pred_robust_test = mg_model.predict(X_test)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals_regular = y - y_pred_regular\n",
    "    residuals_ridge = y - y_pred_ridge\n",
    "    residuals_lasso = y - y_pred_lasso\n",
    "    residuals_robust = y - y_pred_robust\n",
    "    \n",
    "    # Plot regression curves (first subplot)\n",
    "    axes[i,0].scatter(X, y, color='gray', label='Data', zorder=2, alpha=0.3)\n",
    "    axes[i,0].plot(X, y_clean, color='g', alpha=0.1, label='True Data', zorder=2)\n",
    "    axes[i,0].plot(X_test, y_pred_regular_test, 'b--', label='Regular', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_ridge_test, 'g-.', label=f'Ridge', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_lasso_test, 'm:', label=f'Lasso', zorder=1)\n",
    "    axes[i,0].plot(X_test, y_pred_robust_test, 'r-', label='MG', zorder=1)\n",
    "    axes[i,0].set_xlabel('X')\n",
    "    axes[i,0].set_ylabel('y')\n",
    "    axes[i,0].set_title(f'{func.capitalize()} Function')\n",
    "    axes[i,0].legend()\n",
    "    axes[i,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot residuals (second subplot)\n",
    "    axes[i,1].scatter(X, residuals_regular, color='blue', label='Regular', alpha=0.3)\n",
    "    axes[i,1].scatter(X, residuals_ridge, color='green', label='Ridge', alpha=0.63)\n",
    "    axes[i,1].scatter(X, residuals_lasso, color='magenta', label='Lasso', alpha=0.3)\n",
    "    axes[i,1].scatter(X, residuals_robust, color='red', label='MG', alpha=0.3)\n",
    "    axes[i,1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    axes[i,1].set_xlabel('X')\n",
    "    axes[i,1].set_ylabel('Residuals')\n",
    "    axes[i,1].set_title(f'Residuals - {func.capitalize()}')\n",
    "    axes[i,1].legend()\n",
    "    axes[i,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot coefficients comparison (third subplot)\n",
    "    coef_names = [f'θ{j}' for j in range(degree + 1)]\n",
    "    x_pos = np.arange(len(coef_names))\n",
    "    width = 0.2\n",
    "    \n",
    "    # Get coefficients from all models\n",
    "    regular_coef = poly_reg.named_steps['linearregression'].coef_\n",
    "    ridge_coef = ridge_reg.named_steps['ridge'].coef_\n",
    "    lasso_coef = lasso_reg.named_steps['lasso'].coef_\n",
    "    mg_coef = mg_model.coefficients\n",
    "    \n",
    "    # Plot coefficients\n",
    "    axes[i,2].bar(x_pos - 1.5*width, regular_coef, width, label='Regular', color='blue', alpha=0.6)\n",
    "    axes[i,2].bar(x_pos - 0.5*width, ridge_coef, width, label='Ridge', color='green', alpha=0.6)\n",
    "    axes[i,2].bar(x_pos + 0.5*width, lasso_coef, width, label='Lasso', color='magenta', alpha=0.6)\n",
    "    axes[i,2].bar(x_pos + 1.5*width, mg_coef, width, label='MG', color='red', alpha=0.6)\n",
    "    \n",
    "    axes[i,2].set_xlabel('Coefficient')\n",
    "    axes[i,2].set_ylabel('Value')\n",
    "    axes[i,2].set_title(f'Model Coefficients - {func.capitalize()}')\n",
    "    axes[i,2].set_xticks(x_pos)\n",
    "    axes[i,2].set_xticklabels(coef_names)\n",
    "    axes[i,2].legend()\n",
    "    axes[i,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot weights comparison (fourth subplot)\n",
    "    # Use inverse of absolute residuals as weights for traditional methods\n",
    "    reg_weights = 1 / (1 + np.abs(residuals_regular))\n",
    "    ridge_weights = 1 / (1 + np.abs(residuals_ridge))\n",
    "    lasso_weights = 1 / (1 + np.abs(residuals_lasso))\n",
    "    \n",
    "    # Normalize all weights to [0,1]\n",
    "    reg_weights = reg_weights / np.max(reg_weights)\n",
    "    ridge_weights = ridge_weights / np.max(ridge_weights)\n",
    "    lasso_weights = lasso_weights / np.max(lasso_weights)\n",
    "    mg_weights = mg_model.weights / np.max(mg_model.weights)\n",
    "    \n",
    "    axes[i,3].plot(X, reg_weights, 'b--', label='Regular', alpha=0.6)\n",
    "    axes[i,3].plot(X, ridge_weights, 'g-.', label='Ridge', alpha=0.6)\n",
    "    axes[i,3].plot(X, lasso_weights, 'm:', label='Lasso', alpha=0.6)\n",
    "    axes[i,3].plot(X, mg_weights, 'r-', label='MG', alpha=0.6)\n",
    "    axes[i,3].fill_between(X.ravel(), mg_weights, alpha=0.2, color='red')\n",
    "    \n",
    "    axes[i,3].set_xlabel('X')\n",
    "    axes[i,3].set_ylabel('Normalized Weight')\n",
    "    axes[i,3].set_title(f'Weight Comparison - {func.capitalize()}')\n",
    "    axes[i,3].legend()\n",
    "    axes[i,3].grid(True, alpha=0.3)\n",
    "    axes[i,3].set_ylim(0, 1.1)\n",
    "\n",
    "    # Calculate and print metrics\n",
    "    good_indices = np.setdiff1d(np.arange(len(X)), outlier_positions)\n",
    "    mse_regular = np.mean((y_pred_regular[good_indices] - y[good_indices])**2)\n",
    "    mse_ridge = np.mean((y_pred_ridge[good_indices] - y[good_indices])**2)\n",
    "    mse_lasso = np.mean((y_pred_lasso[good_indices] - y[good_indices])**2)\n",
    "    mse_robust = np.mean((y_pred_robust[good_indices] - y[good_indices])**2)\n",
    "    \n",
    "    print(f\"\\n{func.capitalize()} Function:\")\n",
    "    print(f\"MSE (excluding outliers):\")\n",
    "    print(f\"Regular Polynomial: {mse_regular:.4f}\")\n",
    "    print(f\"Ridge Regression:   {mse_ridge:.4f}\")\n",
    "    print(f\"Lasso Regression:   {mse_lasso:.4f}\")\n",
    "    print(f\"Robust MG:          {mse_robust:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196888c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.mg_rig import RobustRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "X = np.linspace(0, 2, 50).reshape(-1, 1)  # More points for smoother curves\n",
    "noise = np.random.normal(0, 0.2, 50)\n",
    "y = 4 * X.ravel() + 1 + noise  # Linear relationship with noise\n",
    "\n",
    "# Add some outliers\n",
    "outlier_idx = [10, 30, 40]\n",
    "y[outlier_idx] += [5.0, -5.0, 16.0]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit models\n",
    "degree = 2\n",
    "# Regular polynomial regression\n",
    "poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "poly_reg.fit(X_train, y_train)\n",
    "y_pred_regular_train = poly_reg.predict(X_train)\n",
    "y_pred_regular_test = poly_reg.predict(X_test)\n",
    "\n",
    "# Fit robust Machine Gnostics regression\n",
    "mg_model = RobustRegressor(degree=degree, mg_loss='hi')\n",
    "mg_model.fit(X_train, y_train)\n",
    "y_pred_robust_train = mg_model.predict(X_train)\n",
    "y_pred_robust_test = mg_model.predict(X_test)\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "# Create figure with subplots with adjusted height ratios\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15), height_ratios=[2, 1, 1])\n",
    "\n",
    "# Plot 1: Training and Test Data with Predictions\n",
    "ax1.scatter(X_train, y_train, c='gray', label='Training Data', alpha=0.6, s=100, zorder=2)\n",
    "ax1.scatter(X_test, y_test, c='red', label='Test Data', alpha=0.6, s=100, zorder=2)\n",
    "\n",
    "# Sort X values for smooth curve plotting\n",
    "X_plot = np.sort(X_train, axis=0)\n",
    "X_test_plot = np.sort(X_test, axis=0)\n",
    "\n",
    "# Plot predictions with smoother curves\n",
    "ax1.plot(X_plot, mg_model.predict(X_plot), 'r-', label='MG', linewidth=2.5, zorder=3)\n",
    "ax1.plot(X_plot, poly_reg.predict(X_plot), 'b--', label='Regular Poly', linewidth=2.5, zorder=3)\n",
    "\n",
    "ax1.set_xlabel('X', fontsize=12)\n",
    "ax1.set_ylabel('y', fontsize=12)\n",
    "ax1.set_title('Model Predictions on Training and Test Data', fontsize=14, pad=20)\n",
    "ax1.legend(fontsize=10, loc='upper left')\n",
    "ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Plot 2: Residuals with clearer visualization\n",
    "residuals_regular = y_train - poly_reg.predict(X_train)\n",
    "residuals_robust = y_train - mg_model.predict(X_train)\n",
    "\n",
    "ax2.scatter(X_train, residuals_regular, c='blue', label='Regular', alpha=0.6, s=80)\n",
    "ax2.scatter(X_train, residuals_robust, c='red', label='MG', alpha=0.6, s=80)\n",
    "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('X', fontsize=12)\n",
    "ax2.set_ylabel('Residuals', fontsize=12)\n",
    "ax2.set_title('Residual Plot', fontsize=14, pad=20)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Plot 3: Loss History with clearer weight visualization\n",
    "ax3.plot(mg_model._history, 'r-', label='Loss', linewidth=2)\n",
    "ax3.set_xlabel('Iteration', fontsize=12)\n",
    "ax3.set_ylabel('Loss', fontsize=12, color='r')\n",
    "ax3.set_title('Loss History and Sample Weights', fontsize=14, pad=20)\n",
    "ax3.tick_params(axis='y', labelcolor='r')\n",
    "ax3.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add sample weights on secondary y-axis with better formatting\n",
    "ax3_twin = ax3.twinx()\n",
    "ax3_twin.plot(range(len(X_train)), mg_model.weights, 'b--', label='Weights', linewidth=2)\n",
    "ax3_twin.fill_between(range(len(X_train)), mg_model.weights, alpha=0.2, color='blue')\n",
    "ax3_twin.set_ylabel('Sample Weights', fontsize=12, color='b')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Add combined legend for loss and weights\n",
    "lines1, labels1 = ax3.get_legend_handles_labels()\n",
    "lines2, labels2 = ax3_twin.get_legend_handles_labels()\n",
    "ax3_twin.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "# Calculate training set metrics\n",
    "mse_regular_train = np.mean((y_pred_regular_train - y_train)**2)\n",
    "mse_robust_train = np.mean((y_pred_robust_train - y_train)**2)\n",
    "\n",
    "# Calculate test set metrics\n",
    "mse_regular_test = np.mean((y_pred_regular_test - y_test)**2)\n",
    "mse_robust_test = np.mean((y_pred_robust_test - y_test)**2)\n",
    "\n",
    "# Print metrics with better formatting\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Training Set:\")\n",
    "print(f\"{'MSE Regular:':<15} {mse_regular_train:.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {mse_robust_train:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"{'MSE Regular:':<15} {mse_regular_test:.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {mse_robust_test:.4f}\")\n",
    "\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Regular: {poly_reg.named_steps['linearregression'].coef_}\")\n",
    "print(f\"MG:      {mg_model.coefficients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f217881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.mg_rig import RobustRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 2D synthetic data\n",
    "n_samples = 100\n",
    "X1 = np.random.uniform(0, 2, n_samples)\n",
    "X2 = np.random.uniform(0, 2, n_samples)\n",
    "X = np.column_stack((X1, X2))\n",
    "\n",
    "# True function: f(X1, X2) = 2*X1 + 3*X2^2 + X1*X2 + 1\n",
    "y_clean = 2*X1 + 3*X2**2 + X1*X2 + 1\n",
    "\n",
    "# Add noise\n",
    "noise = np.random.normal(0, 0.5, n_samples)\n",
    "y = y_clean + noise\n",
    "\n",
    "# Add outliers\n",
    "outlier_idx = [10, 30, 40, 60]\n",
    "y[outlier_idx] += [8.0, -10.0, 15.0, -12.0]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit models\n",
    "degree = 2\n",
    "# Regular polynomial regression\n",
    "poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "poly_reg.fit(X_train, y_train)\n",
    "y_pred_regular_train = poly_reg.predict(X_train)\n",
    "y_pred_regular_test = poly_reg.predict(X_test)\n",
    "\n",
    "# Fit robust Machine Gnostics regression\n",
    "mg_model = RobustRegressor(degree=degree)\n",
    "mg_model.fit(X_train, y_train)\n",
    "y_pred_robust_train = mg_model.predict(X_train)\n",
    "y_pred_robust_test = mg_model.predict(X_test)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Training Data and Residuals\n",
    "scatter = ax1.scatter(X_train[:, 0], X_train[:, 1], c=y_train, \n",
    "                     cmap='viridis', label='Training Data')\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('X2')\n",
    "ax1.set_title('Training Data')\n",
    "plt.colorbar(scatter, ax=ax1, label='y value')\n",
    "\n",
    "# Plot 2: Residuals Comparison\n",
    "residuals_regular = y_train - y_pred_regular_train\n",
    "residuals_robust = y_train - y_pred_robust_train\n",
    "\n",
    "ax2.scatter(X_train[:, 0], residuals_regular, c='blue', label='Regular', alpha=0.6)\n",
    "ax2.scatter(X_train[:, 0], residuals_robust, c='red', label='MG', alpha=0.6)\n",
    "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('X1')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('Residual Plot')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: Loss History and Sample Weights\n",
    "ax3.plot(mg_model._history, 'r-', label='Loss')\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Loss')\n",
    "ax3.set_title('Loss History')\n",
    "\n",
    "# Add sample weights visualization\n",
    "ax3_twin = ax3.twinx()\n",
    "ax3_twin.scatter(range(len(X_train)), mg_model.weights, c='blue', \n",
    "                alpha=0.4, label='Sample Weights')\n",
    "ax3_twin.set_ylabel('Sample Weights', color='blue')\n",
    "\n",
    "# Combine legends\n",
    "lines1, labels1 = ax3.get_legend_handles_labels()\n",
    "lines2, labels2 = ax3_twin.get_legend_handles_labels()\n",
    "ax3_twin.legend(lines1 + lines2, labels1 + labels2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Training Set:\")\n",
    "print(f\"{'MSE Regular:':<15} {np.mean((y_pred_regular_train - y_train)**2):.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {np.mean((y_pred_robust_train - y_train)**2):.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"{'MSE Regular:':<15} {np.mean((y_pred_regular_test - y_test)**2):.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {np.mean((y_pred_robust_test - y_test)**2):.4f}\")\n",
    "\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Regular: {poly_reg.named_steps['linearregression'].coef_}\")\n",
    "print(f\"MG:      {mg_model.coefficients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.mg_rig import RobustRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 2D synthetic data\n",
    "n_samples = 100\n",
    "X1 = np.random.uniform(0, 2, n_samples)\n",
    "X2 = np.random.uniform(0, 2, n_samples)\n",
    "X = np.column_stack((X1, X2))\n",
    "\n",
    "# True function: f(X1, X2) = 2*X1 + 3*X2^2 + X1*X2 + 1\n",
    "y_clean = 2*X1 + 3*X2**2 + X1*X2 + 1\n",
    "\n",
    "# Add noise\n",
    "noise = np.random.normal(0, 0.5, n_samples)\n",
    "y = y_clean + noise\n",
    "\n",
    "# Add outliers\n",
    "outlier_idx = [10, 30, 40, 60]\n",
    "y[outlier_idx] += [8.0, -10.0, 15.0, -12.0]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit models\n",
    "degree = 3\n",
    "# Regular polynomial regression\n",
    "poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "poly_reg.fit(X_train, y_train)\n",
    "y_pred_regular_train = poly_reg.predict(X_train)\n",
    "y_pred_regular_test = poly_reg.predict(X_test)\n",
    "\n",
    "# Fit robust Machine Gnostics regression\n",
    "mg_model = RobustRegressor(degree=degree)\n",
    "mg_model.fit(X_train, y_train)\n",
    "y_pred_robust_train = mg_model.predict(X_train)\n",
    "y_pred_robust_test = mg_model.predict(X_test)\n",
    "\n",
    "# Create figure with subplots arranged vertically\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 12), height_ratios=[2, 1, 1])\n",
    "\n",
    "# Plot 1: Regression Plot (using X1 as x-axis)\n",
    "ax1.scatter(X_train[:, 0], y_train, c='gray', label='Training Data', alpha=0.6)\n",
    "ax1.scatter(X_test[:, 0], y_test, c='lightblue', label='Test Data', alpha=0.6)\n",
    "sort_idx = np.argsort(X_train[:, 0])\n",
    "ax1.plot(X_train[sort_idx, 0], y_pred_regular_train[sort_idx], 'b--', \n",
    "         label='Regular', linewidth=2)\n",
    "ax1.plot(X_train[sort_idx, 0], y_pred_robust_train[sort_idx], 'r-', \n",
    "         label='MG', linewidth=2)\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('Model Predictions')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "residuals_regular = y_train - y_pred_regular_train\n",
    "residuals_robust = y_train - y_pred_robust_train\n",
    "\n",
    "ax2.scatter(X_train[:, 0], residuals_regular, c='blue', label='Regular', alpha=0.6)\n",
    "ax2.scatter(X_train[:, 0], residuals_robust, c='red', label='MG', alpha=0.6)\n",
    "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('X1')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('Residual Plot')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Loss History with Sample Weights\n",
    "ax3.plot(mg_model._history, 'r-', label='Loss', linewidth=2)\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Loss', color='r')\n",
    "ax3.tick_params(axis='y', labelcolor='r')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add sample weights on secondary y-axis\n",
    "ax3_twin = ax3.twinx()\n",
    "ax3_twin.plot(range(len(X_train)), mg_model.weights, 'b--', \n",
    "              label='Weights', linewidth=2)\n",
    "ax3_twin.fill_between(range(len(X_train)), mg_model.weights, \n",
    "                      alpha=0.2, color='blue')\n",
    "ax3_twin.set_ylabel('Sample Weights', color='b')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Combine legends for loss plot\n",
    "lines1, labels1 = ax3.get_legend_handles_labels()\n",
    "lines2, labels2 = ax3_twin.get_legend_handles_labels()\n",
    "ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Training Set:\")\n",
    "print(f\"{'MSE Regular:':<15} {np.mean((y_pred_regular_train - y_train)**2):.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {np.mean((y_pred_robust_train - y_train)**2):.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"{'MSE Regular:':<15} {np.mean((y_pred_regular_test - y_test)**2):.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {np.mean((y_pred_robust_test - y_test)**2):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.mg_rig import RobustRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 3D synthetic data\n",
    "n_samples = 100\n",
    "X1 = np.random.uniform(0, 2, n_samples)\n",
    "X2 = np.random.uniform(0, 2, n_samples)\n",
    "X3 = np.random.uniform(0, 2, n_samples)\n",
    "X = np.column_stack((X1, X2, X3))\n",
    "\n",
    "# True functions: \n",
    "# y1 = 2*X1 + 3*X2^2 + X1*X3 + X2*X3 + 1\n",
    "# y2 = X1^2 + 2*X2 + 3*X3 + X1*X2 - 2\n",
    "y1_clean = 2*X1 + 3*X2**2 + X1*X3 + X2*X3 + 1\n",
    "y2_clean = X1**2 + 2*X2 + 3*X3 + X1*X2 - 2\n",
    "\n",
    "# Add noise\n",
    "noise1 = np.random.normal(0, 0.5, n_samples)\n",
    "noise2 = np.random.normal(0, 0.5, n_samples)\n",
    "y1 = y1_clean + noise1\n",
    "y2 = y2_clean + noise2\n",
    "\n",
    "# Add outliers\n",
    "outlier_idx = [10, 30, 40, 60]\n",
    "y1[outlier_idx] += [8.0, -10.0, 15.0, -12.0]\n",
    "y2[outlier_idx] += [-12.0, 15.0, -8.0, 10.0]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y1_train, y1_test, y2_train, y2_test = train_test_split(\n",
    "    X, y1, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit models for y1 and y2\n",
    "degree = 3\n",
    "\n",
    "# Regular polynomial regression\n",
    "poly_reg1 = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "poly_reg2 = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "\n",
    "poly_reg1.fit(X_train, y1_train)\n",
    "poly_reg2.fit(X_train, y2_train)\n",
    "\n",
    "y1_pred_regular_train = poly_reg1.predict(X_train)\n",
    "y1_pred_regular_test = poly_reg1.predict(X_test)\n",
    "y2_pred_regular_train = poly_reg2.predict(X_train)\n",
    "y2_pred_regular_test = poly_reg2.predict(X_test)\n",
    "\n",
    "# Fit robust Machine Gnostics regression\n",
    "mg_model1 = RobustRegressor(degree=degree)\n",
    "mg_model2 = RobustRegressor(degree=degree)\n",
    "\n",
    "mg_model1.fit(X_train, y1_train)\n",
    "mg_model2.fit(X_train, y2_train)\n",
    "\n",
    "y1_pred_robust_train = mg_model1.predict(X_train)\n",
    "y1_pred_robust_test = mg_model1.predict(X_test)\n",
    "y2_pred_robust_train = mg_model2.predict(X_train)\n",
    "y2_pred_robust_test = mg_model2.predict(X_test)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "\n",
    "# Plot predictions for y1 and y2\n",
    "for idx, (y_train, y_test, y_pred_regular_train, y_pred_robust_train, title) in enumerate([\n",
    "    (y1_train, y1_test, y1_pred_regular_train, y1_pred_robust_train, 'y1'),\n",
    "    (y2_train, y2_test, y2_pred_regular_train, y2_pred_robust_train, 'y2')\n",
    "]):\n",
    "    # Predictions plot\n",
    "    axes[0, idx].scatter(y_train, y_pred_regular_train, c='blue', \n",
    "                        label='Regular', alpha=0.6)\n",
    "    axes[0, idx].scatter(y_train, y_pred_robust_train, c='red', \n",
    "                        label='MG', alpha=0.6)\n",
    "    axes[0, idx].plot([y_train.min(), y_train.max()], \n",
    "                     [y_train.min(), y_train.max()], 'k--', alpha=0.5)\n",
    "    axes[0, idx].set_xlabel(f'True {title}')\n",
    "    axes[0, idx].set_ylabel(f'Predicted {title}')\n",
    "    axes[0, idx].set_title(f'Predictions for {title}')\n",
    "    axes[0, idx].legend()\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "\n",
    "    # Residuals plot\n",
    "    residuals_regular = y_train - y_pred_regular_train\n",
    "    residuals_robust = y_train - y_pred_robust_train\n",
    "    \n",
    "    axes[1, idx].scatter(X_train[:, 0], residuals_regular, c='blue', \n",
    "                        label='Regular', alpha=0.6)\n",
    "    axes[1, idx].scatter(X_train[:, 0], residuals_robust, c='red', \n",
    "                        label='MG', alpha=0.6)\n",
    "    axes[1, idx].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[1, idx].set_xlabel('X1')\n",
    "    axes[1, idx].set_ylabel(f'Residuals ({title})')\n",
    "    axes[1, idx].set_title(f'Residual Plot for {title}')\n",
    "    axes[1, idx].legend()\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "    # Loss and weights plot\n",
    "    mg_model = mg_model1 if idx == 0 else mg_model2\n",
    "    ax = axes[2, idx]\n",
    "    ax.plot(mg_model._history, 'r-', label='Loss', linewidth=2)\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('Loss', color='r')\n",
    "    ax.tick_params(axis='y', labelcolor='r')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add sample weights\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.plot(range(len(X_train)), mg_model.weights, 'b--', \n",
    "                label='Weights', linewidth=2)\n",
    "    ax_twin.fill_between(range(len(X_train)), mg_model.weights, \n",
    "                        alpha=0.2, color='blue')\n",
    "    ax_twin.set_ylabel('Sample Weights', color='b')\n",
    "    ax_twin.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "    # Combine legends\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax_twin.get_legend_handles_labels()\n",
    "    ax.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Training Set:\")\n",
    "print(\"y1:\")\n",
    "print(f\"{'MSE Regular:':<15} {np.mean((y1_pred_regular_train - y1_train)**2):.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {np.mean((y1_pred_robust_train - y1_train)**2):.4f}\")\n",
    "print(\"\\ny2:\")\n",
    "print(f\"{'MSE Regular:':<15} {np.mean((y2_pred_regular_train - y2_train)**2):.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {np.mean((y2_pred_robust_train - y2_train)**2):.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(\"y1:\")\n",
    "print(f\"{'MSE Regular:':<15} {np.mean((y1_pred_regular_test - y1_test)**2):.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {np.mean((y1_pred_robust_test - y1_test)**2):.4f}\")\n",
    "print(\"\\ny2:\")\n",
    "print(f\"{'MSE Regular:':<15} {np.mean((y2_pred_regular_test - y2_test)**2):.4f}\")\n",
    "print(f\"{'MSE MG:':<15} {np.mean((y2_pred_robust_test - y2_test)**2):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a3055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
