{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b8607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Get the absolute path to the project root\n",
    "# notebook_path = Path('/Users/nirmal/Documents/np_research/ManGo_code/ManGo')\n",
    "# project_root = str(notebook_path)\n",
    "\n",
    "# # Add the project root to Python path if it's not already there\n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.insert(0, project_root)\n",
    "\n",
    "# # Now you can import your module\n",
    "# from src.models.mg_rig_wrp import GnosticRobustRegressor\n",
    "\n",
    "# # Verify the import worked\n",
    "# # print(f\"Project root: {project_root}\")\n",
    "# # print(f\"Available at: {RobustRegressor.__module__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc52ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 21:30:44,609 | PolynomialRegressor | INFO | PolynomialRegressor initialized:\n",
      "2025-09-23 21:30:44,612 | PolynomialRegressor | INFO | DataProcessLayerBase initialized.\n",
      "2025-09-23 21:30:44,614 | PolynomialRegressor | INFO | DataProcessRobustRegressor initialized.\n",
      "2025-09-23 21:30:44,615 | PolynomialRegressor | DEBUG | PolynomialRegressor initialized.\n",
      "2025-09-23 21:30:44,617 | PolynomialRegressor | INFO | Starting fit process.\n",
      "2025-09-23 21:30:44,617 | PolynomialRegressor | INFO | Starting fit process for DataProcessRobustRegressor.\n",
      "2025-09-23 21:30:44,618 | PolynomialRegressor | INFO | Starting fit input/output processing.\n",
      "2025-09-23 21:30:44,618 | PolynomialRegressor | INFO | Checking input X of type: <class 'numpy.ndarray'>\n",
      "2025-09-23 21:30:44,618 | PolynomialRegressor | INFO | Identifying and converting data of type: <class 'numpy.ndarray'>\n",
      "2025-09-23 21:30:44,618 | PolynomialRegressor | INFO | Checking target y of type: <class 'numpy.ndarray'>\n",
      "2025-09-23 21:30:44,619 | PolynomialRegressor | INFO | Identifying and converting data of type: <class 'numpy.ndarray'>\n",
      "2025-09-23 21:30:44,619 | PolynomialRegressor | INFO | Starting fit process for InterfaceRobustRegressor. Logging to MLflow available.\n",
      "2025-09-23 21:30:44,620 | PolynomialRegressor | INFO | Starting fit process for HistoryRobustRegressor.\n",
      "2025-09-23 21:30:44,620 | PolynomialRegressor | INFO | Starting fit process for ParamRobustRegressorBase.\n",
      "2025-09-23 21:30:44,620 | PolynomialRegressor | INFO | Generating polynomial features of degree\n",
      "2025-09-23 21:30:44,621 | PolynomialRegressor | INFO | Generated polynomial features shape: (100, 10)\n",
      "2025-09-23 21:30:44,621 | PolynomialRegressor | INFO | Initializing weights with method: one\n",
      "2025-09-23 21:30:44,622 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,626 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,628 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,629 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,633 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,634 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,634 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,635 | PolynomialRegressor | INFO | Iteration: 1 - Machine Gnostic loss - hi : 90.3947, rentropy: 0.5891\n",
      "2025-09-23 21:30:44,635 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,636 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,636 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,636 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,638 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,638 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,638 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,639 | PolynomialRegressor | INFO | Iteration: 2 - Machine Gnostic loss - hi : 90.5862, rentropy: 0.5729\n",
      "2025-09-23 21:30:44,639 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,639 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,640 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,640 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,641 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,641 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,642 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,642 | PolynomialRegressor | INFO | Iteration: 3 - Machine Gnostic loss - hi : 90.4289, rentropy: 0.6185\n",
      "2025-09-23 21:30:44,642 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,642 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,643 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,643 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,644 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,644 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,645 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,646 | PolynomialRegressor | INFO | Iteration: 4 - Machine Gnostic loss - hi : 90.8347, rentropy: 0.6381\n",
      "2025-09-23 21:30:44,647 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,647 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,648 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,648 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,650 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,650 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,650 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,651 | PolynomialRegressor | INFO | Iteration: 5 - Machine Gnostic loss - hi : 90.4825, rentropy: 0.6869\n",
      "2025-09-23 21:30:44,652 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,653 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,654 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,654 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,656 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,656 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,657 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,659 | PolynomialRegressor | INFO | Iteration: 6 - Machine Gnostic loss - hi : 91.008, rentropy: 0.5679\n",
      "2025-09-23 21:30:44,659 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,660 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,660 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,660 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,662 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,663 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,665 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,665 | PolynomialRegressor | INFO | Iteration: 7 - Machine Gnostic loss - hi : 91.1959, rentropy: 0.5578\n",
      "2025-09-23 21:30:44,666 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,666 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,667 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,667 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,668 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,669 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,670 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,670 | PolynomialRegressor | INFO | Iteration: 8 - Machine Gnostic loss - hi : 90.952, rentropy: 0.6494\n",
      "2025-09-23 21:30:44,670 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,670 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,670 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,671 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,672 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,672 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,672 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,672 | PolynomialRegressor | INFO | Iteration: 9 - Machine Gnostic loss - hi : 90.6694, rentropy: 0.6895\n",
      "2025-09-23 21:30:44,672 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,673 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,673 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,673 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,674 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,674 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,674 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,675 | PolynomialRegressor | INFO | Iteration: 10 - Machine Gnostic loss - hi : 90.5058, rentropy: 0.7046\n",
      "2025-09-23 21:30:44,675 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,675 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,675 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,675 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,676 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,676 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,677 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,677 | PolynomialRegressor | INFO | Iteration: 11 - Machine Gnostic loss - hi : 90.4612, rentropy: 0.709\n",
      "2025-09-23 21:30:44,677 | PolynomialRegressor | INFO | Solving weighted least squares.\n",
      "2025-09-23 21:30:44,677 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,678 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,678 | PolynomialRegressor | INFO | Converting data using form: a\n",
      "2025-09-23 21:30:44,679 | PolynomialRegressor | INFO | Computing gnostic criterion.\n",
      "2025-09-23 21:30:44,679 | PolynomialRegressor | INFO | Computing q and q1 for gnostic criterion.\n",
      "2025-09-23 21:30:44,679 | PolynomialRegressor | INFO | Computing gnostic criterion for 'hi' loss.\n",
      "2025-09-23 21:30:44,680 | PolynomialRegressor | INFO | Iteration: 12 - Machine Gnostic loss - hi : 90.4767, rentropy: 0.7091\n",
      "2025-09-23 21:30:44,680 | PolynomialRegressor | INFO | Convergence reached at iteration 12 with loss/rentropy change below tolerance.\n",
      "2025-09-23 21:30:44,685 | PolynomialRegressor | INFO | Making predictions.\n",
      "2025-09-23 21:30:44,685 | PolynomialRegressor | INFO | Making predictions with DataProcessRobustRegressor.\n",
      "2025-09-23 21:30:44,686 | PolynomialRegressor | INFO | Starting predict input/output processing.\n",
      "2025-09-23 21:30:44,686 | PolynomialRegressor | INFO | Checking input X for prediction of type: <class 'pandas.core.frame.DataFrame'>\n",
      "2025-09-23 21:30:44,686 | PolynomialRegressor | INFO | Checking input X of type: <class 'pandas.core.frame.DataFrame'>\n",
      "2025-09-23 21:30:44,686 | PolynomialRegressor | INFO | Identifying and converting data of type: <class 'pandas.core.frame.DataFrame'>\n",
      "2025-09-23 21:30:44,686 | PolynomialRegressor | INFO | Making predictions with InterfaceRobustRegressor.\n",
      "2025-09-23 21:30:44,686 | PolynomialRegressor | INFO | Starting prediction for ParamRobustRegressorBase.\n",
      "2025-09-23 21:30:44,687 | PolynomialRegressor | INFO | Generating polynomial features of degree\n",
      "2025-09-23 21:30:44,687 | PolynomialRegressor | INFO | Generated polynomial features shape: (100, 10)\n",
      "2025/09/23 21:30:44 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "2025/09/23 21:30:48 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2025-04-15; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'machinegnostics'}\n",
      "2025-09-23 21:30:48,305 | PolynomialRegressor | INFO | Making predictions.\n",
      "2025-09-23 21:30:48,306 | PolynomialRegressor | INFO | Making predictions with DataProcessRobustRegressor.\n",
      "2025-09-23 21:30:48,306 | PolynomialRegressor | INFO | Starting predict input/output processing.\n",
      "2025-09-23 21:30:48,306 | PolynomialRegressor | INFO | Checking input X for prediction of type: <class 'pandas.core.frame.DataFrame'>\n",
      "2025-09-23 21:30:48,306 | PolynomialRegressor | INFO | Checking input X of type: <class 'pandas.core.frame.DataFrame'>\n",
      "2025-09-23 21:30:48,307 | PolynomialRegressor | INFO | Identifying and converting data of type: <class 'pandas.core.frame.DataFrame'>\n",
      "2025-09-23 21:30:48,307 | PolynomialRegressor | INFO | Making predictions with InterfaceRobustRegressor.\n",
      "2025-09-23 21:30:48,307 | PolynomialRegressor | INFO | Starting prediction for ParamRobustRegressorBase.\n",
      "2025-09-23 21:30:48,307 | PolynomialRegressor | INFO | Generating polynomial features of degree\n",
      "2025-09-23 21:30:48,308 | PolynomialRegressor | INFO | Generated polynomial features shape: (100, 10)\n",
      "Successfully registered model 'GnosticRobustRegressor'.\n",
      "Created version '1' of model 'GnosticRobustRegressor'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "from machinegnostics.models.regression import PolynomialRegressor\n",
    "import numpy as np\n",
    "# Create and train the model\n",
    "model = PolynomialRegressor(degree=3, mg_loss='hi', verbose=True)\n",
    "X = np.random.rand(100, 2)\n",
    "y = np.random.rand(100)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Create an input example\n",
    "input_example = pd.DataFrame(X, columns=[\"feature1\", \"feature2\"])\n",
    "\n",
    "# Infer the model signature\n",
    "signature = infer_signature(input_example, model.predict( input_example))\n",
    "\n",
    "# Log the model to MLflow with input_example and signature\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"robust_regressor\",\n",
    "        python_model=model,\n",
    "        registered_model_name=\"GnosticRobustRegressor\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e362e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert history to DataFrame if it's a list of dicts\n",
    "if isinstance(model._history, list):\n",
    "    history_df = pd.DataFrame(model._history)\n",
    "else:\n",
    "    history_df = pd.DataFrame([model._history])\n",
    "\n",
    "# Plot h_loss if present\n",
    "if 'h_loss' in history_df.columns and history_df['h_loss'].notnull().any():\n",
    "    plt.plot(history_df['iteration'], history_df['h_loss'], label='h_loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('h_loss')\n",
    "    plt.title('Gnostic Loss (h_loss) over Iterations')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot rentropy if present\n",
    "if 'rentropy' in history_df.columns and history_df['rentropy'].notnull().any():\n",
    "    plt.plot(history_df['iteration'], history_df['rentropy'], label='rentropy', color='orange')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Rentropy')\n",
    "    plt.title('Residual Entropy over Iterations')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot coefficients norm if present\n",
    "if 'coefficients' in history_df.columns and history_df['coefficients'].notnull().any():\n",
    "    coef_norms = history_df['coefficients'].apply(lambda x: np.linalg.norm(x) if x is not None else np.nan)\n",
    "    plt.plot(history_df['iteration'], coef_norms, label='||coefficients||', color='green')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Coefficient Norm')\n",
    "    plt.title('Coefficient Norm over Iterations')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot mean weights if present\n",
    "if 'weights' in history_df.columns and history_df['weights'].notnull().any():\n",
    "    mean_weights = history_df['weights'].apply(lambda x: np.mean(x) if x is not None else np.nan)\n",
    "    plt.plot(history_df['iteration'], mean_weights, label='Mean Weights', color='red')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Mean Weight')\n",
    "    plt.title('Mean Sample Weight over Iterations')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from MLflow\n",
    "loaded_model = mlflow.pyfunc.load_model(\"models:/GnosticRobustRegressor/1\")\n",
    "\n",
    "# Use the model for predictions\n",
    "import pandas as pd\n",
    "X_test = pd.DataFrame(np.random.rand(10, 2), columns=[\"feature1\", \"feature2\"])\n",
    "predictions = loaded_model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "from machinegnostics.models import RobustRegressor  # Replace with your actual import path\n",
    "\n",
    "# Step 1: Set up MLflow experiment\n",
    "# mlflow.set_experiment(\"Robust Regressor Experiment\")\n",
    "\n",
    "# Step 2: Generate synthetic data\n",
    "X = np.random.rand(100, 2)  # 100 samples, 2 features\n",
    "y = 2.5 * X[:, 0] + 1.5 * X[:, 1] + np.random.normal(scale=0.1, size=100)  # Linear relationship with noise\n",
    "\n",
    "# Step 3: Train the model\n",
    "model = RobustRegressor(degree=3, mg_loss='hi', verbose=True)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Step 4: Create an input example and infer the model signature\n",
    "input_example = pd.DataFrame(X, columns=[\"feature1\", \"feature2\"])\n",
    "signature = infer_signature(model_input=input_example, model_output=y)\n",
    "\n",
    "# Step 5: Log the model, parameters, and metrics to MLflow\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"degree\", 3)\n",
    "    mlflow.log_param(\"mg_loss\", \"hi\")\n",
    "    mlflow.log_param(\"verbose\", True)\n",
    "\n",
    "    # Log metrics (example: training RMSE)\n",
    "    y_pred = model.predict(input_example)\n",
    "    rmse = np.sqrt(np.mean((y - y_pred) ** 2))\n",
    "    mlflow.log_metric(\"train_rmse\", rmse)\n",
    "\n",
    "    # Safely log rentropy and h_loss if available and not None\n",
    "    rentropy = None\n",
    "    h_loss = None\n",
    "    if hasattr(model, \"_history\"):\n",
    "        hist = model._history\n",
    "        # If history is a dict of lists\n",
    "        if isinstance(hist, dict):\n",
    "            if \"rentropy\" in hist and hist[\"rentropy\"] and hist[\"rentropy\"][-1] is not None:\n",
    "                rentropy = hist[\"rentropy\"][-1]\n",
    "            if \"h_loss\" in hist and hist[\"h_loss\"] and hist[\"h_loss\"][-1] is not None:\n",
    "                h_loss = hist[\"h_loss\"][-1]\n",
    "        # If history is a list of dicts\n",
    "        elif isinstance(hist, list) and len(hist) > 0:\n",
    "            if \"rentropy\" in hist[-1] and hist[-1][\"rentropy\"] is not None:\n",
    "                rentropy = hist[-1][\"rentropy\"]\n",
    "            if \"h_loss\" in hist[-1] and hist[-1][\"h_loss\"] is not None:\n",
    "                h_loss = hist[-1][\"h_loss\"]\n",
    "\n",
    "    if rentropy is not None:\n",
    "        mlflow.log_metric('train_rentropy', rentropy)\n",
    "    if h_loss is not None:\n",
    "        mlflow.log_metric('train_h_loss', h_loss)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"robust_regressor\",\n",
    "        python_model=model,\n",
    "        registered_model_name=\"LogisticRobustRegressor\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f980a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save_model(\"robust_regressor_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc232cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read model and make predictions\n",
    "loaded_model = model.load_model(\"robust_regressor_model.pkl\")\n",
    "# Use the loaded model for predictions\n",
    "X_test = pd.DataFrame(np.random.rand(10, 2), columns=[\"feature1\", \"feature2\"])\n",
    "predictions = loaded_model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5678066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Load the model from MLflow\n",
    "loaded_model = mlflow.pyfunc.load_model(\"models:/LogisticRobustRegressor/4\")\n",
    "\n",
    "# Step 7: Use the loaded model for predictions\n",
    "# X_test = pd.DataFrame(np.random.rand(10, 2), columns=[\"feature1\", \"feature2\"])\n",
    "predictions = loaded_model.predict(X_test)\n",
    "print(\"Predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02243105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
